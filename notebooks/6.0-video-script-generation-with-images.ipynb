{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Script Generation with AI-Generated Images\n",
    "\n",
    "In this notebook, we'll create a complete workflow for generating educational video scripts about research papers, including AI-generated visual elements.\n",
    "\n",
    "## What You'll Learn\n",
    "- How to use the OpenAI Responses API to generate structured video scripts\n",
    "- How to create image prompts for educational visuals\n",
    "- How to generate images using OpenAI's Image Generation API\n",
    "- How to combine text and visuals for video content\n",
    "\n",
    "## Use Case\n",
    "Creating educational videos about research papers requires:\n",
    "1. A well-structured script that explains complex concepts simply\n",
    "2. Visual aids that help illustrate key ideas\n",
    "3. Scene-by-scene planning for video production\n",
    "\n",
    "Let's automate this process using AI!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, we'll import the necessary libraries and set up our OpenAI client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from pypdf import PdfReader\n",
    "import base64\n",
    "from IPython.display import Image, display, Markdown\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Video Script Structure\n",
    "\n",
    "We'll use Pydantic to define what a video script should contain. This ensures our AI generates well-structured output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScriptScene(BaseModel):\n",
    "    \"\"\"Represents a single scene in the video script.\"\"\"\n",
    "    scene_number: int = Field(description=\"The scene number (1, 2, 3, etc.)\")\n",
    "    narration: str = Field(description=\"What the narrator says in this scene (1-3 sentences)\")\n",
    "    image_prompt: str = Field(description=\"Detailed prompt for generating a visual for this scene\")\n",
    "\n",
    "class VideoScript(BaseModel):\n",
    "    \"\"\"Complete video script with title and scenes.\"\"\"\n",
    "    title: str = Field(description=\"Catchy title for the video\")\n",
    "    hook: str = Field(description=\"Opening hook to grab attention (1 sentence)\")\n",
    "    scenes: List[ScriptScene] = Field(description=\"List of 4-5 scenes that explain the paper\")\n",
    "    conclusion: str = Field(description=\"Closing statement (1-2 sentences)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a Research Paper\n",
    "\n",
    "We'll use a helper function to extract text from a PDF research paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_text(file_path):\n",
    "    \"\"\"Loads text from a PDF file.\"\"\"\n",
    "    reader = PdfReader(file_path)\n",
    "    text = \"\\n\\n\".join([page.extract_text() for page in reader.pages])\n",
    "    return text\n",
    "\n",
    "# Load the Word2Vec paper\n",
    "paper_text = load_pdf_text(\"../assets/paper3.pdf\")\n",
    "\n",
    "print(f\"Loaded paper with {len(paper_text)} characters\")\n",
    "print(f\"First 200 characters: {paper_text[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the Video Script\n",
    "\n",
    "Now we'll use the Responses API with structured outputs to generate a complete video script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instructions for the AI\n",
    "instructions = \"\"\"\n",
    "You are an expert at creating educational video scripts about research papers.\n",
    "Your scripts should be:\n",
    "- Simple and engaging for a general audience\n",
    "- Clear and easy to follow\n",
    "- Visual-friendly (describe what viewers should see)\n",
    "\"\"\"\n",
    "\n",
    "# Generate the script using structured outputs\n",
    "response = client.responses.parse(\n",
    "    model=\"gpt-5-mini\",\n",
    "    instructions=instructions,\n",
    "    input=f\"Create a 60-second educational video script about this research paper. Make it engaging and visual:\\n\\n{paper_text}\",\n",
    "    text_format=VideoScript\n",
    ")\n",
    "\n",
    "# Extract the structured script\n",
    "script = response.output_parsed\n",
    "\n",
    "print(f\"Generated script: '{script.title}'\")\n",
    "print(f\"Number of scenes: {len(script.scenes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the Script\n",
    "\n",
    "Let's see what the AI generated!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the script as markdown\n",
    "script_md = f\"\"\"\n",
    "# {script.title}\n",
    "\n",
    "## Opening Hook\n",
    "{script.hook}\n",
    "\n",
    "## Scenes\n",
    "\"\"\"\n",
    "\n",
    "for scene in script.scenes:\n",
    "    script_md += f\"\"\"\n",
    "### Scene {scene.scene_number}\n",
    "**Narration:** {scene.narration}\n",
    "\n",
    "**Visual:** {scene.image_prompt}\n",
    "\n",
    "---\n",
    "\"\"\"\n",
    "\n",
    "script_md += f\"\"\"\n",
    "## Conclusion\n",
    "{script.conclusion}\n",
    "\"\"\"\n",
    "\n",
    "display(Markdown(script_md))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Images for Each Scene\n",
    "\n",
    "Now we'll use OpenAI's Image Generation API to create visuals for each scene in our script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_scene_image(scene, output_folder=\"../assets/video_images\"):\n",
    "    \"\"\"\n",
    "    Generate an image for a video scene using DALL-E.\n",
    "    \n",
    "    Args:\n",
    "        scene: ScriptScene object with image_prompt\n",
    "        output_folder: Where to save the generated images\n",
    "    \n",
    "    Returns:\n",
    "        Path to the saved image file\n",
    "    \"\"\"\n",
    "    import os\n",
    "    \n",
    "    # Create output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    print(f\"Generating image for Scene {scene.scene_number}...\")\n",
    "    \n",
    "    # Generate the image\n",
    "    img_response = client.images.generate(\n",
    "        model=\"gpt-image-1\",\n",
    "        prompt=scene.image_prompt,\n",
    "        n=1,\n",
    "        size=\"1024x1024\"\n",
    "    )\n",
    "    \n",
    "    # Decode and save the image\n",
    "    image_bytes = base64.b64decode(img_response.data[0].b64_json)\n",
    "    output_path = f\"{output_folder}/scene_{scene.scene_number}.png\"\n",
    "    \n",
    "    with open(output_path, \"wb\") as f:\n",
    "        f.write(image_bytes)\n",
    "    \n",
    "    print(f\"âœ“ Saved to {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "# Generate images for all scenes\n",
    "image_paths = []\n",
    "for scene in script.scenes:\n",
    "    path = generate_scene_image(scene)\n",
    "    image_paths.append(path)\n",
    "\n",
    "print(f\"\\nGenerated {len(image_paths)} images!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the Complete Video Storyboard\n",
    "\n",
    "Let's see our script with the generated images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the complete storyboard\n",
    "print(f\"VIDEO STORYBOARD: {script.title}\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nOPENING HOOK: {script.hook}\\n\")\n",
    "\n",
    "for scene, img_path in zip(script.scenes, image_paths):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"SCENE {scene.scene_number}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Narration: {scene.narration}\\n\")\n",
    "    display(Image(filename=img_path, width=400))\n",
    "    print()\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"CONCLUSION: {script.conclusion}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "In this notebook, you learned:\n",
    "\n",
    "1. **Structured Outputs**: Using Pydantic models with `responses.parse()` ensures the AI generates exactly the format you need\n",
    "2. **Image Generation**: The `images.generate()` API creates custom visuals from text descriptions\n",
    "3. **Workflow Automation**: Combining text and image generation creates a complete content pipeline\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Try modifying this notebook to:\n",
    "- Generate scripts for different paper types\n",
    "- Adjust the number of scenes\n",
    "- Experiment with different image styles in the prompts\n",
    "- Add voice-over timing to each scene"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
